"GPU_PTX"


{%(*
  \paragraph{Barrier heirarchy}
  We define the hierarchy of memory barriers.
  The $X${\tt -fence} relation relates events
  that are separated by a fence of scope $X$
  or wider.
%*)}

let sys-fence = membar.sys
let gl-fence  = membar.gl  | sys-fence
let cta-fence = membar.cta | gl-fence


{%(*
  \paragraph{SC-per-location with load-load hazard}
  We require that communications do not
  contradict program order, unless the events
  are for different locations, or both events
  are reads. We allow cta-level memory barriers to return full per-location SC.
%*)}



let com = rf | fr | co
(* let po-loc-llh = WW(po-loc) | WR(po-loc) | RW(po-loc) *)
(* let po-loc-llh = po-loc & ((W * W) | (W * R) | (R * W)) *)
let po-loc-llh = po-loc & ((M * W) | (W * M))
let RRfence = po-loc & (R * R) & cta-fence
acyclic (po-loc-llh | com | RRfence) as sc-per-loc-llh



{%(*
  \paragraph{Atomicity}
  This ensures that read-modify-write accesses are read and write atomically in coherence order.
%*)}


empty rmw & (fre;coe)

{%(*
  \paragraph{No thin air}
  This prevents causal loops. No event
  may read from its dependants.
%*)}

let dp = addr | data | ctrl
acyclic (dp | rf) as no-thin-air



{%(*
  \paragraph{Scoped RMO}
  We declare a generic {\tt rmo} relation, and
  instantiate it for each scope. We implement
  RMO-per-scope by requiring each of these
  relations to be acyclic.
%*)}

let rmo(r,fence) = dp | rfe | co | fr | r?;fence;r?
let rmo-cta = rmo(id,      cta-fence) & cta
let rmo-gl  = rmo(rmo-cta+, gl-fence)  & gl
let rmo-sys = rmo(rmo-gl+,  sys-fence)

acyclic rmo-cta as cta-constraint
acyclic rmo-gl as gl-constraint
acyclic rmo-sys as sys-constraint
